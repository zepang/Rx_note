# Getting Node.js Apps Production Ready

Getting Node.js apps to a production-ready statu is probably the most unexplored and skipped topic in the Node.js literature.The reason could be the lack of expertise in production deployments or the vast number of options and edge cases.However, getting apps to the production level is one of themost important topics in this entire book in my humble opinion.

Yesm the apps differ in structures, the frameworks they use, and the goals they try to achieve;however, there are a few commonalities worth knowing about -- for example, environmental variables, multithreading,logging, and error handling.So, in this charpter, we cover the following topics:

* Environment varibles
* Express.js in production
* Socket.IO in production
* Error handling
* Node.js domains for error handling
* Multithreading with Cluster
* Multithreading with pm2
* Event logging and monitoring
* Building tasks with Grunt
* Locking dependencies
* Git for version control and deployments
* Running tests in Cloud with TravisCI

# Environment Variables
Sensitive information such as API keys, passwords, and database URIs are best stored in environment variables, not in the source code iteself.Node.js makes it fairly easy to access these variables:

```js
console.log(process.env.NODE_ENV,
process.env.API_KEY,
process.env.DB_PASSWORD)
```

Then, before the application is startedm, set these variables:

```
NODE_ENV=test API_KEY=XYZ DB_PASSWORD=ABC node envvar.js
```
Typically, the environment variables setting is a part of the deployment or operations setup.In the next cahpter, we deal with puttin these variables on the server.

# Express.js in Production

In Express.js, use if/else statements to check for `NODE_ENV` values to use different levels of server logs.For development, we want more information, but in production, stack and exceptions might reveal a vulneability, so we hide them:
```js
const errorHandler = require('errorhandler')
if (process.env.NODE_ENV === 'development') {
  app.use(errorHandler({
    dumpExceptions: true,
    showStack: true
  }))
} else {
  app.use(errorHandler())
}
```
let's talk about sessions now.When using in-memory session store (the default choice),the data can't be shared across different processes/servers (which we want in production mode).Conveniently, Express.js and Connect nofify us about this as we see in this source code with the message:
```
Warning: connect.session() MemoryStore is not
designed for a production environment, as it will leak
memory, and will not scale past a single process.
```
What we need here is single source of the truth---one location where all the session data is sotred an can be acessed by mutiple Node servers.This problem is solved easily by using a shared Redis instance as a session store.For example, for Express.js, execute the following:
```js
const session = require('express-session')
const RedisStore = require('connect-redis')(session)

app.use(session({
  sotre: new RedisStore(options),
  secret: process.env.SESSION_SECRET
}))
```
There is a more advanced example with session options that inclueds a special key and cookie domain:
```js
const SessionStore = require('connect-redis')
const session = require('express-session')

app.use(session({
  key: process.env.SESSION_KEY,
  secret: process.env.SESSION_SECRET,
  store: new SessionStore({
    cookie: { domain: '.webapplog.com' },
    db: 1,
    host: 'webapplog.com'
  })
}))
```
Options for `connect-redis` are client, host, port, ttl, db, pass, prefix, and url.For more information, please refer to the official `connect-redis` [documentation(https://github.com/visionmedia/connect-redis)](https://github.com/visionmedia/connect-redis)

# Error Handling

As a rule of thumb, when readying your code for production, make sure to listen to all error event from `http.server` and `https.Server`, i.e., always have error event listeners foing something like this:

```js
server.on('error', (err) => {
  console.log(err)
})
```

Then have catchall envent listener(`uncaughtExceptions`) for unforeseen case.This event is the last step before the app will crash, terminate the process, and burn your computer to ashes.Do not try to resume a nirmal operation when you have this event.Log, save work(if you have anything left), and exit like this:

```js
process.on('uncaughtException', (err) => {
  console.error('uncaughtException: ', err.message)
  console.error(err.stack)
  process.exit(1)
})

// Alternatively, you can use the `addListener` method
process.addListener('uncaughtException', (err) => {
  console.error('uncaughtException: ', err.message)
  console.error(err.stack)
  process.exit(1)
})
```

Cover a more advanced alternative to the `console.log` -- the [Winston library(https://github.com/winstonjs/winston)](https://github.com/winstonjs/winston)

# Multithreading with Cluster
With the core `cluster` module[(http://nodejs.org/api/cluster.html)](http://nodejs.org/api/cluster.html), we can spawn many Node.js processes effortlessly to handle the system;s load.These individual processes use the same source code, and they can listen to the same port.Typically, each process uses one machine's CPU.There's a master process that spawns all other processes and, in a way, controls them(it can kill, restart, and so on).

```js
const cluster = require('cluster')
const http = require('http')
const numCPUs = require('os').cpus().length
const express = requrie('express')
```
The `cluster` module has a property that tell us whether the process is master or child (master control child).We use it to spawn four workers.In addition, we can attach event listeners and receive messages from workers(e.g., `kill`)
```js
if (cluster.isMaster) {
  console.log('Fork %s worker(s) from master', numCPUs)
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork()
  }
  cluster.on('online', (worker) => {
    console.log('worker is running on %s pid', worker.process.pid)
  })
  cluster.on('exit', (worker, code, signal) => {
    console.log('worker with %s closed', worker.process.pid)
  })
} else {
  const port = 3000
  console.log(`worker (${cluster.worker.process.pid}) is now listening to http://localhost:${port}`)
  const app = express()
  app.get('*', (req, res) => {
    res.send(200, `caluster ${cluster.worker.process.pid} responed \n`)
  })
  app.listen(port)
}
```

# Multitireading with pm2

Achieving multithreading with `pm2` is even simpler than with cluster beacuse there's no need modify the source code. `pm2` will pick up your `server.js` file and fork it into multiple processes.Each process will be listening on the same port, so your system will have load balanced between the processes.`pm2` goes into the background becasue it works as a service.You can name each set of processes, view, restart,or stop them.

```
npm i -g pm2

<!-- Onece you have `pm2`, use `start` command with the option `-i 0`, which means automatically determine the number of CPUs an launch that many processes. -->
pm2 start -i 0 app.js
pm2 ls
pm2 stop all
```

# Event logging and Monitoring

When things go south(e.g., memory leaks, overloads, crashes), there are two things software engineers can do:
  1. Monitor via dashboard and health statuses
  2. Analyze postmortems after the events have happened

### Monitoring
---
When going to production, software and development operations engineers need a way to get current status quickly.Having a dashboard or just an endpoint that spits out JSON-formatted properties is a good idea, including properties such as the following:
* `memoryUsage`: Memory usage information
* `uptime`: Number of seconds the Node.js process is running
* `pid`: Process ID
* `cannections`: Number of connections
* `loadavg`: Load average
* `sha`: Secure Hash Algorithm(SHA) of the Git commit deploy and/or version tag of the deploy

Here's an example of the Express.js route `/status`

```js
app.get('status', (req, res) => {
  res.send({`
    pid: process.pid,`
    memory: process.memoryUsage(),`
    uptime: process.uptime()
  })
})
```

A more informative example with connections and other information is as follows:

```js
const os = require('os')
const exec = require('child_process').exec
const async = require('async')
const started_at = new Date()

module.exports = (req, res, next) => {
  const server = req.app
  if (req.param('info')) {
    let connections = {}
    let swap

    async.parallel([
      (done) => {
        exec('nestat -an | grep :80 | wc -l', (e, res) => {
          connections['80'] = parseInt(res, 10)
          done()
        })
      },
      done => {
        exec(
          'netstat -an | grep :'
          + server.set('port')
          + ' | wc -l',
          (e, res) => {
            connections[server.set('port')] = parseInt(res, 10)
            done()
          }
        )
      },
      (done) => {
        exec('vmstat -SM -s | grep "used swap" | sed -E "s/[^0-9]*([0-9]{1,8}).*/\1/"', (e, res) => {
          swap = res
          done()
        })
      }
    ], e => {
      res.send({
        status: 'up',
        version: server.get('version'), 
        sha: server.et('git sha'), 
        started_at: started_at, 
        node: {
          version: process.version,
          memoryUsage: Math.round(process.memoryUsage().rss / 1024 / 1024)+"M",
          uptime: process.uptime() 
        }, 
        system: {
          loadavg: os.loadavg(),
          freeMemory: Math.round(os.freemem()/1024/1024)+"M"
        },
        env: process.env.NODE_ENV,
        hostname: os.hostname(),
        connections: connections,
        swap: swap
      })
    })
  } else {
    res.send({status: 'up'})
  }
}
```

# REPL in Production
What can be better than poking around a live process and its context using the REPL tool? We can do this easily with production app if we set up REPL as server.

```js
const net = require('net')
const options = {name: 'azat'}

net.createServer(function (socket) => {
  repl.start(options.name + '>', socket).context.app = app
}).listen('/tmp/repl-app-' + options.name)
```

Then, connect to the remote machine by using Secure Shell(SSH).Once on the remote machine, run:
```
telnet /tmp/repl-app-azat
```

You should be prompted with a more sign(`>`),which means you;re in the REPL.

Or, if you want to connect to the remote server right away, i.e.,bypassing the SSH step, you can modify the code to this:
```js
const repl = require('repl')
const net = require('net')
const options = { name: 'azat' }
const app = {a: 1}
net.createServer(function(socket) {
  repl.start(options.name + "> ", socket).context.app = app
}).listen(3000)
```
Please use iptable to restrict the Internet protocol addresses (IPs) when using this approach. Then, straight from your local machine (where the hostname is the IP of the remote box), execute:
```
telnet hostname 3000
```
# Winston
Winston is an abstraction layer for the server logs.

It's easy to get started with Winston.Install it into your project:
```
npm i -SE winston
```
In the code, implement the import and then you can log:
```js
var winston = require('winston')
winston.log('info', 'Hello distributed log files')
winston.info('Hello again distributed logs')
```

The power of Winston comes when you add tranporters.To add and remove transporters, use the `winston.add()` and `winston.remove()` functions.

To add a file trasporter, provide a file name:
```js
winston.add(winston.tranports.File, {filename: 'webapp.log'})
```
For more information, go to the official documentation [(https://github.com/flatiron/winston#working-with-transports)](https://github.com/flatiron/winston#working-with-transports).

# Papertrail App for Logging
[Papertrail(https://papertrailapp.com)](https://papertrailapp.com) is a SaaS that provides centrlized storage and a web GUI to search and analyze logs.To use Papertrail with the Node.js app, do the following.
1. Write logs to file and [remote_sync (https://github.com/papertrail/remote_syslog) ](https://github.com/papertrail/remote_syslog) them to Papertail
2. Send logs with [winston (https://github.com/flatiron/winston#working-with-transports)](https://github.com/flatiron/winston#working-with-transports), which is described earlier, and [winston-papertrail(https://github.com/kenperkins/winston-papertrail)](https://github.com/kenperkins/winston-papertrail), directly to the service.

# Building Tasks with Grunt

# A Brief on Webpack

# Locking Dependencies

# Git for Version Control and Deployments

# Run tests in cloud with [travisCI(https://travis-ci.org.)](https://travis-ci.org.)
TravisCI is an SaaS continuous integration system that allows you to automate testing on each GitHub push (e.g., $ git push origin master). Alternative services include [Codeship (https://www.codeship.io)]((https://www.codeship.io)), [CircleCI (https://circleci.com)]((https://circleci.com)), and many others [(http://bit.ly/1ipdxxt)](http://bit.ly/1ipdxxt).